


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt




# Merge dataframes
twox = pd.read_csv('./data/two_x.csv')
mrm = pd.read_csv('./data/mrm.csv')

posts = pd.concat([twox, mrm], ignore_index=True)


posts.head()
print(posts.dtypes)


# Clean up the NaN values
# in this case, valuable info is in the title
# sometimes self text is brief and the key info is in the self_text
# TODO: so we should include titles in the analysis
twox['self_text'] = twox['self_text'].fillna('')


full_text = '\n\n'.join(twox['self_text'])


# Count the most frequent words
# adapted from https://stackoverflow.com/questions/29903025/count-most-frequent-100-words-from-sentences-in-dataframe-pandas
pd.Series(full_text.split()).value_counts()[:100]


twox['title'].isna().sum() # titles are always required, no nulls

#= twox['self_text'].fillna('')


# convert utc to datetime

twox['created_utc'] = pd.to_datetime(posts['created_utc'][3], unit='s')


twox.head()


# ROWAN what other kinds of EDA make sense - check on titanic lab


# TODO drop rows where post has been removed


# Repeat cleaning for MRM
# then export cleaned csvs


# Confirm no nulls at the end before writing to csv
