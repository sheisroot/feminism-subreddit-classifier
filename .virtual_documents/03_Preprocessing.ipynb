


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline

from sklearn.naive_bayes import MultinomialNB

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
# we may choose to only optimize for Tfidf bc this structures the data with more information 
from nltk.corpus import stopwords





posts = pd.read_csv('./data/posts.csv')
posts = posts.fillna('')
posts['subreddit'] = posts['subreddit'].map({'TwoXChromosomes': 1, 'MensRights': 0})
posts.tail()


posts.isnull().sum() # confirm data contains no null values


# engineer a new feature that combines title and self text 'all_text'
# because oftentimes posts have no text body, and the title contains all the information
posts['all_text'] = posts['title'] + '\n\n' + posts['self_text']
posts['all_text']


dropped = posts.drop(columns=['title', 'self_text'])
dropped = dropped[['created_utc', 'all_text', 'subreddit']]
dropped.head()


dropped = dropped.sample(frac=1, random_state=2043) # shuffled the concatenated dfs
dropped.to_csv('./data/posts_cleaned.csv', index=False)
dropped.head()





# Start from here
posts = pd.read_csv('./data/posts_cleaned.csv')
posts.head()


posts.subreddit.mean() # 0.50 means balanced classes which is good for binary classification





X = posts['all_text']
y = posts['subreddit']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)


# Set up a pipeline with two stages:
# 1. CountVectorizer (transformer)
# 2. Multinomial Naive Bayes (estimator)

# Given the warning in CountVectorizer that their stop_words for 'english' are not great, we use the nltk library stop_words
sw = stopwords.words('english')

pipe = Pipeline([
    ('cvec', CountVectorizer()),
    ('nb', MultinomialNB())
])

params = {
    'cvec__stop_words' :[None, sw],
    # 'cvec__binary': [False, True],
    'cvec__min_df': [1, 2],
    # 'cvec__max_df: [0.98]
    'cvec__ngram_range': [(1, 1), (1, 2), (2, 3)],
    'cvec__max_features': [1000, 2000, 3000, None],
}

gs = GridSearchCV(pipe, params, n_jobs=8)


%%time
gs.fit(X_train, y_train)





# HERE
# RELEVANT EDA - consult 405-classification metrics to discuss the confusion matrix and to plot distributions, consult 502-lab-nlp to see what kind of EDA
gs.best_params_


pd.DataFrame(gs.cv_results_).sort_values('mean_test_score', ascending=False)[:5]


gs.score(X_train, y_train)


gs.score(X_test, y_test)


y_hat = gs.predict(X_test)
confusion_matrix(y_test, y_hat)


ConfusionMatrixDisplay.from_estimator(gs, X_test, y_test, cmap='Blues');





# Examine the best params
gs.best_params_





sw


gs.best_estimator_


gs.best_index_


gs.best_score_





# Given the warning in CountVectorizer that their stop_words for 'english' are not great, we use the nltk library stop_words
sw = stopwords.words('english')

pipe = Pipeline([
    ('cvec', CountVectorizer()),
    ('nb', MultinomialNB())
])

params = {
    'cvec__stop_words' :[sw],
    # 'cvec__binary': [False, True],
    'cvec__min_df': [1, 2],
    # 'cvec__max_df: [0.98]
    'cvec__ngram_range': [(1,1), (1,2), (1, 3)],
    # 'cvec__max_features': [2000, 3000, None],
}

gs = GridSearchCV(pipe, params, n_jobs=4)


%%time
gs.fit(X_train, y_train)


gs.score(X_train, y_train)


gs.score(X_test, y_test)





ConfusionMatrixDisplay.from_estimator(gs, X_test, y_test, cmap='Blues');


gs.best_params_


# Given the warning in CountVectorizer that their stop_words for 'english' are not great, we use the nltk library stop_words
sw = stopwords.words('english')

pipe = Pipeline([
    ('cvec', CountVectorizer()),
    ('nb', MultinomialNB())
])

params = {
    'cvec__stop_words' :[None],
    # 'cvec__binary': [False, True],
    'cvec__min_df': [1, 2],
    # 'cvec__max_df: [0.98]
    'cvec__ngram_range': [ (1,2)],
    'cvec__max_features': [2000, 3000, None],
}

gs = GridSearchCV(pipe, params, n_jobs=4)


%%time
gs.fit(X_train, y_train)


gs.best_params_


gs.score(X_train, y_train)


gs.score(X_test, y_test)



